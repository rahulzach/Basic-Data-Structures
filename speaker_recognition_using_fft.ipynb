{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 881667,
          "sourceType": "datasetVersion",
          "datasetId": 470244
        }
      ],
      "dockerImageVersionId": 30646,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulzach/Data_Structures/blob/main/speaker_recognition_using_fft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'speaker-recognition-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F470244%2F881667%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240213%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240213T170642Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D5726f82e0d9666a57598257ea7db777f479ca136bbea25424b365edc397adb06d2576b7afb9d2a5ef8ecacf289dcd23c914bed457b0961bc34af55f27ac22b8bd8157fdd727d5b5d751e6d04880053d2c59e15817af360dbd9babde179e1d15b7b6c6034ec5ab30594d2cec49a6f6d5d90d992e8bdc4d772a0e6561eaa4788914d60a5162bfc5f86c98c398069ebbf8d1ee5c8f1ec47c047c2f78cd8a0ca0e6a73cc7c8ee0cf541faa355306f939312399af63ea14f7ea6c40d45397ad2ac9bef1664cae8a97eb172ee569c3132861e3f639edb463e835ef8cbcfb11d0e7766b64c274c61c8579c2ab3803863d0117addea246b86ff87ed71753df3a36cef4ae'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "5S2ab_PEb2uZ",
        "outputId": "83926684-5548-4eca-f930-a31409546ab1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading speaker-recognition-dataset, 241803761 bytes compressed\n",
            "[==================================================] 241803761 bytes downloaded\n",
            "Downloaded and uncompressed: speaker-recognition-dataset\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from os.path import isfile, join\n",
        "import numpy as np\n",
        "import shutil\n",
        "from tensorflow import keras\n",
        "from pathlib import Path\n",
        "from IPython.display import display, Audio\n",
        "import subprocess"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-02-13T13:53:56.759662Z",
          "iopub.execute_input": "2024-02-13T13:53:56.760148Z",
          "iopub.status.idle": "2024-02-13T13:53:56.766541Z",
          "shell.execute_reply.started": "2024-02-13T13:53:56.760115Z",
          "shell.execute_reply": "2024-02-13T13:53:56.765439Z"
        },
        "trusted": true,
        "id": "fX9_ySNmb2ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"../input/speaker-recognition-dataset\" ./"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T13:54:06.269471Z",
          "iopub.execute_input": "2024-02-13T13:54:06.269916Z",
          "iopub.status.idle": "2024-02-13T13:54:59.893894Z",
          "shell.execute_reply.started": "2024-02-13T13:54:06.269884Z",
          "shell.execute_reply": "2024-02-13T13:54:59.89212Z"
        },
        "trusted": true,
        "id": "5iSXrvi3b2ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_directory = \"./speaker-recognition-dataset/16000_pcm_speeches\"\n",
        "audio_folder = \"audio\"\n",
        "noise_folder = \"noise\"\n",
        "\n",
        "audio_path = os.path.join(data_directory, audio_folder)\n",
        "noise_path = os.path.join(data_directory, noise_folder)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T13:55:17.097025Z",
          "iopub.execute_input": "2024-02-13T13:55:17.097559Z",
          "iopub.status.idle": "2024-02-13T13:55:17.104826Z",
          "shell.execute_reply.started": "2024-02-13T13:55:17.09752Z",
          "shell.execute_reply": "2024-02-13T13:55:17.103482Z"
        },
        "trusted": true,
        "id": "TadoO-7Yb2uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_path"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T13:55:24.445209Z",
          "iopub.execute_input": "2024-02-13T13:55:24.445955Z",
          "iopub.status.idle": "2024-02-13T13:55:24.454117Z",
          "shell.execute_reply.started": "2024-02-13T13:55:24.445915Z",
          "shell.execute_reply": "2024-02-13T13:55:24.453227Z"
        },
        "trusted": true,
        "id": "VvPVXcyLb2uc",
        "outputId": "ca18959b-408f-4640-e3f5-214b5bbd3a17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./speaker-recognition-dataset/16000_pcm_speeches/audio'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_split = 0.1\n",
        "shuffle_seed = 43\n",
        "sample_rate = 16000\n",
        "scale = 0.5\n",
        "batch_size = 128\n",
        "epochs = 15"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T13:55:28.918263Z",
          "iopub.execute_input": "2024-02-13T13:55:28.919441Z",
          "iopub.status.idle": "2024-02-13T13:55:28.925698Z",
          "shell.execute_reply.started": "2024-02-13T13:55:28.919402Z",
          "shell.execute_reply": "2024-02-13T13:55:28.924449Z"
        },
        "trusted": true,
        "id": "Cvxq913Rb2uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for folder in os.listdir(data_directory):\n",
        "    if os.path.isdir(os.path.join(data_directory, folder)):\n",
        "        if folder in [audio_folder, noise_folder]:\n",
        "\n",
        "            continue\n",
        "        elif folder in [\"other\", \"_background_noise_\"]:\n",
        "\n",
        "            shutil.move(\n",
        "                os.path.join(data_directory, folder),\n",
        "                os.path.join(noise_path, folder),\n",
        "            )\n",
        "        else:\n",
        "            shutil.move(\n",
        "                os.path.join(data_directory, folder),\n",
        "                os.path.join(audio_path, folder),\n",
        "            )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T13:55:33.458568Z",
          "iopub.execute_input": "2024-02-13T13:55:33.459646Z",
          "iopub.status.idle": "2024-02-13T13:55:33.818207Z",
          "shell.execute_reply.started": "2024-02-13T13:55:33.459607Z",
          "shell.execute_reply": "2024-02-13T13:55:33.817078Z"
        },
        "trusted": true,
        "id": "rHHCO8SKb2uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise_paths = []\n",
        "for subdir in os.listdir(noise_path):\n",
        "    subdir_path = Path(noise_path) / subdir\n",
        "    if os.path.isdir(subdir_path):\n",
        "        noise_paths += [\n",
        "            os.path.join(subdir_path, filepath)\n",
        "            for filepath in os.listdir(subdir_path)\n",
        "            if filepath.endswith(\".wav\")\n",
        "        ]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T13:55:38.561953Z",
          "iopub.execute_input": "2024-02-13T13:55:38.562389Z",
          "iopub.status.idle": "2024-02-13T13:55:38.569522Z",
          "shell.execute_reply.started": "2024-02-13T13:55:38.562357Z",
          "shell.execute_reply": "2024-02-13T13:55:38.568389Z"
        },
        "trusted": true,
        "id": "9KC54R-Bb2uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise_paths"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T13:55:43.194049Z",
          "iopub.execute_input": "2024-02-13T13:55:43.194445Z",
          "iopub.status.idle": "2024-02-13T13:55:43.202814Z",
          "shell.execute_reply.started": "2024-02-13T13:55:43.194414Z",
          "shell.execute_reply": "2024-02-13T13:55:43.201677Z"
        },
        "trusted": true,
        "id": "cKU1ZZr5b2ud",
        "outputId": "d302d0b9-54a2-4a5a-e5d9-bb98185164a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['speaker-recognition-dataset/16000_pcm_speeches/noise/_background_noise_/10convert.com_Audience-Claps_daSG5fwdA7o.wav',\n",
              " 'speaker-recognition-dataset/16000_pcm_speeches/noise/_background_noise_/running_tap.wav',\n",
              " 'speaker-recognition-dataset/16000_pcm_speeches/noise/_background_noise_/doing_the_dishes.wav',\n",
              " 'speaker-recognition-dataset/16000_pcm_speeches/noise/_background_noise_/dude_miaowing.wav',\n",
              " 'speaker-recognition-dataset/16000_pcm_speeches/noise/other/exercise_bike.wav',\n",
              " 'speaker-recognition-dataset/16000_pcm_speeches/noise/other/pink_noise.wav']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "command = (\n",
        "    \"for dir in `ls -1 \" + noise_path + \"`; do \"\n",
        "    \"for file in `ls -1 \" + noise_path + \"/$dir/*.wav`; do \"\n",
        "    \"sample_rate=`ffprobe -hide_banner -loglevel panic -show_streams \"\n",
        "    \"$file | grep sample_rate | cut -f2 -d=`; \"\n",
        "    \"if [ $sample_rate -ne 16000 ]; then \"\n",
        "    \"ffmpeg -hide_banner -loglevel panic -y \"\n",
        "    \"-i $file -ar 16000 temp.wav; \"\n",
        "    \"mv temp.wav $file; \"\n",
        "    \"fi; done; done\"\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T13:55:48.5728Z",
          "iopub.execute_input": "2024-02-13T13:55:48.573241Z",
          "iopub.status.idle": "2024-02-13T13:55:48.580547Z",
          "shell.execute_reply.started": "2024-02-13T13:55:48.57321Z",
          "shell.execute_reply": "2024-02-13T13:55:48.579609Z"
        },
        "trusted": true,
        "id": "AJJ3NhRpb2ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.system(command)\n",
        "def load_noise_sample(path):\n",
        "    sample, sampling_rate = tf.audio.decode_wav(\n",
        "        tf.io.read_file(path), desired_channels=1\n",
        "    )\n",
        "    if sampling_rate == sample_rate:\n",
        "        slices = int(sample.shape[0] / sample_rate)\n",
        "        sample = tf.split(sample[: slices * sample_rate], slices)\n",
        "        return sample\n",
        "    else:\n",
        "        print(\"Sampling rate for\",path, \"is incorrect\")\n",
        "        return None\n",
        "\n",
        "\n",
        "noises = []\n",
        "for path in noise_paths:\n",
        "    sample = load_noise_sample(path)\n",
        "    if sample:\n",
        "        noises.extend(sample)\n",
        "noises = tf.stack(noises)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T13:55:53.010986Z",
          "iopub.execute_input": "2024-02-13T13:55:53.011369Z",
          "iopub.status.idle": "2024-02-13T13:55:55.172764Z",
          "shell.execute_reply.started": "2024-02-13T13:55:53.011341Z",
          "shell.execute_reply": "2024-02-13T13:55:55.171608Z"
        },
        "trusted": true,
        "id": "6YzejZE7b2ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def paths_and_labels_to_dataset(audio_paths, labels):\n",
        "    path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n",
        "    audio_ds = path_ds.map(lambda x: path_to_audio(x))\n",
        "    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
        "    return tf.data.Dataset.zip((audio_ds, label_ds))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T13:56:00.313845Z",
          "iopub.execute_input": "2024-02-13T13:56:00.314261Z",
          "iopub.status.idle": "2024-02-13T13:56:00.32271Z",
          "shell.execute_reply.started": "2024-02-13T13:56:00.314231Z",
          "shell.execute_reply": "2024-02-13T13:56:00.321094Z"
        },
        "trusted": true,
        "id": "fFtS2svvb2ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def path_to_audio(path):\n",
        "    audio = tf.io.read_file(path)\n",
        "    audio, _ = tf.audio.decode_wav(audio, 1, sample_rate)\n",
        "    return audio"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T13:56:04.621617Z",
          "iopub.execute_input": "2024-02-13T13:56:04.622114Z",
          "iopub.status.idle": "2024-02-13T13:56:04.629413Z",
          "shell.execute_reply.started": "2024-02-13T13:56:04.62207Z",
          "shell.execute_reply": "2024-02-13T13:56:04.627975Z"
        },
        "trusted": true,
        "id": "Xo9C4ZTlb2ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_noise(audio, noises=None, scale=0.5):\n",
        "    if noises is not None:\n",
        "        tf_rnd = tf.random.uniform(\n",
        "            (tf.shape(audio)[0],), 0, noises.shape[0], dtype=tf.int32\n",
        "        )\n",
        "        noise = tf.gather(noises, tf_rnd, axis=0)\n",
        "\n",
        "        prop = tf.math.reduce_max(audio, axis=1) / tf.math.reduce_max(noise, axis=1)\n",
        "        prop = tf.repeat(tf.expand_dims(prop, axis=1), tf.shape(audio)[1], axis=1)\n",
        "\n",
        "        audio = audio + noise * prop * scale\n",
        "\n",
        "    return audio"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T13:56:08.971438Z",
          "iopub.execute_input": "2024-02-13T13:56:08.971846Z",
          "iopub.status.idle": "2024-02-13T13:56:08.981324Z",
          "shell.execute_reply.started": "2024-02-13T13:56:08.971815Z",
          "shell.execute_reply": "2024-02-13T13:56:08.979886Z"
        },
        "trusted": true,
        "id": "w9Onww4Sb2ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def audio_to_fft(audio):\n",
        "    audio = tf.squeeze(audio, axis=-1)\n",
        "    fft = tf.signal.fft(\n",
        "        tf.cast(tf.complex(real=audio, imag=tf.zeros_like(audio)), tf.complex64)\n",
        "    )\n",
        "    fft = tf.expand_dims(fft, axis=-1)\n",
        "\n",
        "    return tf.math.abs(fft[:, : (audio.shape[1] // 2), :])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T13:56:14.216551Z",
          "iopub.execute_input": "2024-02-13T13:56:14.216945Z",
          "iopub.status.idle": "2024-02-13T13:56:14.225425Z",
          "shell.execute_reply.started": "2024-02-13T13:56:14.216916Z",
          "shell.execute_reply": "2024-02-13T13:56:14.223963Z"
        },
        "trusted": true,
        "id": "w27kt8Wab2ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = os.listdir(audio_path)\n",
        "print(class_names,)\n",
        "\n",
        "audio_paths = []\n",
        "labels = []\n",
        "for label, name in enumerate(class_names):\n",
        "    print(\"Speaker:\",(name))\n",
        "    dir_path = Path(audio_path) / name\n",
        "    speaker_sample_paths = [\n",
        "        os.path.join(dir_path, filepath)\n",
        "        for filepath in os.listdir(dir_path)\n",
        "        if filepath.endswith(\".wav\")\n",
        "    ]\n",
        "    audio_paths += speaker_sample_paths\n",
        "    labels += [label] * len(speaker_sample_paths)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T13:56:22.011535Z",
          "iopub.execute_input": "2024-02-13T13:56:22.011989Z",
          "iopub.status.idle": "2024-02-13T13:56:22.049538Z",
          "shell.execute_reply.started": "2024-02-13T13:56:22.01195Z",
          "shell.execute_reply": "2024-02-13T13:56:22.047595Z"
        },
        "trusted": true,
        "id": "5KV0gxsPb2ue",
        "outputId": "46b7e592-ac57-4be8-d294-071cb6442c18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Benjamin_Netanyau', 'Nelson_Mandela', 'Jens_Stoltenberg', 'Julia_Gillard', 'Magaret_Tarcher']\n",
            "Speaker: Benjamin_Netanyau\n",
            "Speaker: Nelson_Mandela\n",
            "Speaker: Jens_Stoltenberg\n",
            "Speaker: Julia_Gillard\n",
            "Speaker: Magaret_Tarcher\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle to generate random data\n",
        "rng = np.random.RandomState(shuffle_seed)\n",
        "rng.shuffle(audio_paths)\n",
        "rng = np.random.RandomState(shuffle_seed)\n",
        "rng.shuffle(labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T13:56:30.528403Z",
          "iopub.execute_input": "2024-02-13T13:56:30.529611Z",
          "iopub.status.idle": "2024-02-13T13:56:30.538311Z",
          "shell.execute_reply.started": "2024-02-13T13:56:30.529572Z",
          "shell.execute_reply": "2024-02-13T13:56:30.536982Z"
        },
        "trusted": true,
        "id": "OeAMB2vYb2ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training and validation\n",
        "num_val_samples = int(valid_split * len(audio_paths))\n",
        "train_audio_paths = audio_paths[:-num_val_samples]\n",
        "train_labels = labels[:-num_val_samples]\n",
        "\n",
        "\n",
        "valid_audio_paths = audio_paths[-num_val_samples:]\n",
        "valid_labels = labels[-num_val_samples:]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T13:56:34.469109Z",
          "iopub.execute_input": "2024-02-13T13:56:34.46957Z",
          "iopub.status.idle": "2024-02-13T13:56:34.477695Z",
          "shell.execute_reply.started": "2024-02-13T13:56:34.469534Z",
          "shell.execute_reply": "2024-02-13T13:56:34.476283Z"
        },
        "trusted": true,
        "id": "-PEPOB4Jb2ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create datasets, one for training and the other for validation\n",
        "train_ds = paths_and_labels_to_dataset(train_audio_paths, train_labels)\n",
        "train_ds = train_ds.shuffle(buffer_size=batch_size * 8, seed=shuffle_seed).batch(\n",
        "    batch_size\n",
        ")\n",
        "\n",
        "valid_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\n",
        "valid_ds = valid_ds.shuffle(buffer_size=32 * 8, seed=shuffle_seed).batch(32)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T13:56:39.08035Z",
          "iopub.execute_input": "2024-02-13T13:56:39.081238Z",
          "iopub.status.idle": "2024-02-13T13:56:39.286203Z",
          "shell.execute_reply.started": "2024-02-13T13:56:39.081182Z",
          "shell.execute_reply": "2024-02-13T13:56:39.285083Z"
        },
        "trusted": true,
        "id": "WcXgpIkdb2ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add noise to the training set\n",
        "train_ds = train_ds.map(\n",
        "    lambda x, y: (add_noise(x, noises, scale=scale), y),\n",
        "    num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
        ")\n",
        "\n",
        "# Transform audio wave to the frequency domain using `audio_to_fft`\n",
        "train_ds = train_ds.map(\n",
        "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        ")\n",
        "\n",
        "train_ds = train_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "valid_ds = valid_ds.map(\n",
        "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        ")\n",
        "valid_ds = valid_ds.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T13:56:42.977484Z",
          "iopub.execute_input": "2024-02-13T13:56:42.977926Z",
          "iopub.status.idle": "2024-02-13T13:56:43.393917Z",
          "shell.execute_reply.started": "2024-02-13T13:56:42.977895Z",
          "shell.execute_reply": "2024-02-13T13:56:43.392699Z"
        },
        "trusted": true,
        "id": "-xwd0i6pb2uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv1D"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T13:56:48.264247Z",
          "iopub.execute_input": "2024-02-13T13:56:48.264667Z",
          "iopub.status.idle": "2024-02-13T13:56:48.400432Z",
          "shell.execute_reply.started": "2024-02-13T13:56:48.264637Z",
          "shell.execute_reply": "2024-02-13T13:56:48.399161Z"
        },
        "trusted": true,
        "id": "Vn-10Kkub2uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(x, filters, conv_num = 3, activation = \"relu\"):\n",
        "    s = keras.layers.Conv1D(filters, 1, padding = \"same\")(x)\n",
        "\n",
        "    for i in range(conv_num - 1):\n",
        "        x = keras.layers.Conv1D(filters, 3, padding = \"same\")(x)\n",
        "        x = keras.layers.Activation(activation)(x)\n",
        "\n",
        "    x = keras.layers.Conv1D(filters, 3, padding = \"same\")(x)\n",
        "    x = keras.layers.Add()([x, s])\n",
        "    x = keras.layers.Activation(activation)(x)\n",
        "\n",
        "    return keras.layers.MaxPool1D(pool_size = 2, strides = 2)(x)\n",
        "\n",
        "def build_model(input_shape, num_classes):\n",
        "    inputs = keras.layers.Input(shape = input_shape, name = \"input\")\n",
        "\n",
        "    x = residual_block(inputs, 16, 2)\n",
        "    x = residual_block(inputs, 32, 2)\n",
        "    x = residual_block(inputs, 64, 3)\n",
        "    x = residual_block(inputs, 128, 3)\n",
        "    x = residual_block(inputs, 128, 3)\n",
        "    x = keras.layers.AveragePooling1D(pool_size=3, strides=3)(x)\n",
        "    x = keras.layers.Flatten()(x)\n",
        "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
        "\n",
        "    outputs = keras.layers.Dense(num_classes, activation = \"softmax\", name = \"output\")(x)\n",
        "\n",
        "    return keras.models.Model(inputs = inputs, outputs = outputs)\n",
        "\n",
        "model = build_model((sample_rate // 2, 1), len(class_names))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model_save_filename = \"model.h5\"\n",
        "\n",
        "earlystopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "\n",
        "mdlcheckpoint_cb = keras.callbacks.ModelCheckpoint(model_save_filename, monitor=\"val_accuracy\", save_best_only=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T13:56:52.295579Z",
          "iopub.execute_input": "2024-02-13T13:56:52.295987Z",
          "iopub.status.idle": "2024-02-13T13:56:53.382213Z",
          "shell.execute_reply.started": "2024-02-13T13:56:52.295955Z",
          "shell.execute_reply": "2024-02-13T13:56:53.38104Z"
        },
        "trusted": true,
        "id": "cVoQNQ8ob2uf",
        "outputId": "76a37e4b-037b-461f-845c-f85e3268579c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input (InputLayer)          [(None, 8000, 1)]            0         []                            \n",
            "                                                                                                  \n",
            " conv1d_15 (Conv1D)          (None, 8000, 128)            512       ['input[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)  (None, 8000, 128)            0         ['conv1d_15[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_16 (Conv1D)          (None, 8000, 128)            49280     ['activation_10[0][0]']       \n",
            "                                                                                                  \n",
            " activation_11 (Activation)  (None, 8000, 128)            0         ['conv1d_16[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_17 (Conv1D)          (None, 8000, 128)            49280     ['activation_11[0][0]']       \n",
            "                                                                                                  \n",
            " conv1d_14 (Conv1D)          (None, 8000, 128)            256       ['input[0][0]']               \n",
            "                                                                                                  \n",
            " add_4 (Add)                 (None, 8000, 128)            0         ['conv1d_17[0][0]',           \n",
            "                                                                     'conv1d_14[0][0]']           \n",
            "                                                                                                  \n",
            " activation_12 (Activation)  (None, 8000, 128)            0         ['add_4[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling1d_4 (MaxPoolin  (None, 4000, 128)            0         ['activation_12[0][0]']       \n",
            " g1D)                                                                                             \n",
            "                                                                                                  \n",
            " average_pooling1d (Average  (None, 1333, 128)            0         ['max_pooling1d_4[0][0]']     \n",
            " Pooling1D)                                                                                       \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 170624)               0         ['average_pooling1d[0][0]']   \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 256)                  4368000   ['flatten[0][0]']             \n",
            "                                                          0                                       \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 128)                  32896     ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " output (Dense)              (None, 5)                    645       ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 43812869 (167.13 MB)\n",
            "Trainable params: 43812869 (167.13 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=epochs,\n",
        "    validation_data=valid_ds,\n",
        "    callbacks=[earlystopping_cb, mdlcheckpoint_cb],\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T13:57:00.341198Z",
          "iopub.execute_input": "2024-02-13T13:57:00.341634Z",
          "iopub.status.idle": "2024-02-13T16:28:46.999749Z",
          "shell.execute_reply.started": "2024-02-13T13:57:00.341596Z",
          "shell.execute_reply": "2024-02-13T16:28:46.995883Z"
        },
        "trusted": true,
        "id": "Nkj3rR3Zb2uf",
        "outputId": "68ad75c1-67c7-4dba-ab57-15db4f87008f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "53/53 [==============================] - ETA: 0s - loss: 16.3938 - accuracy: 0.6021"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r53/53 [==============================] - 37s 562ms/step - loss: 16.3938 - accuracy: 0.6021 - val_loss: 0.3078 - val_accuracy: 0.8787\n",
            "Epoch 2/15\n",
            "53/53 [==============================] - 25s 461ms/step - loss: 0.2648 - accuracy: 0.9016 - val_loss: 0.1451 - val_accuracy: 0.9360\n",
            "Epoch 3/15\n",
            "53/53 [==============================] - 26s 488ms/step - loss: 0.1596 - accuracy: 0.9407 - val_loss: 0.1163 - val_accuracy: 0.9587\n",
            "Epoch 4/15\n",
            "53/53 [==============================] - 26s 489ms/step - loss: 0.0942 - accuracy: 0.9656 - val_loss: 0.0789 - val_accuracy: 0.9800\n",
            "Epoch 5/15\n",
            "53/53 [==============================] - 20s 372ms/step - loss: 0.0821 - accuracy: 0.9714 - val_loss: 0.0818 - val_accuracy: 0.9773\n",
            "Epoch 6/15\n",
            "53/53 [==============================] - 20s 372ms/step - loss: 0.0942 - accuracy: 0.9661 - val_loss: 0.0749 - val_accuracy: 0.9800\n",
            "Epoch 7/15\n",
            "53/53 [==============================] - 20s 371ms/step - loss: 0.0698 - accuracy: 0.9756 - val_loss: 0.1247 - val_accuracy: 0.9573\n",
            "Epoch 8/15\n",
            "53/53 [==============================] - 20s 379ms/step - loss: 0.0611 - accuracy: 0.9784 - val_loss: 0.0791 - val_accuracy: 0.9733\n",
            "Epoch 9/15\n",
            "53/53 [==============================] - 20s 373ms/step - loss: 0.0424 - accuracy: 0.9864 - val_loss: 0.0766 - val_accuracy: 0.9773\n",
            "Epoch 10/15\n",
            "53/53 [==============================] - 20s 375ms/step - loss: 0.0401 - accuracy: 0.9868 - val_loss: 0.0891 - val_accuracy: 0.9787\n",
            "Epoch 11/15\n",
            "53/53 [==============================] - 31s 582ms/step - loss: 0.0619 - accuracy: 0.9779 - val_loss: 0.0535 - val_accuracy: 0.9933\n",
            "Epoch 12/15\n",
            "53/53 [==============================] - 20s 373ms/step - loss: 0.0338 - accuracy: 0.9886 - val_loss: 0.0845 - val_accuracy: 0.9800\n",
            "Epoch 13/15\n",
            "53/53 [==============================] - 21s 382ms/step - loss: 0.0308 - accuracy: 0.9893 - val_loss: 0.0687 - val_accuracy: 0.9840\n",
            "Epoch 14/15\n",
            "53/53 [==============================] - 21s 384ms/step - loss: 0.0700 - accuracy: 0.9772 - val_loss: 0.0634 - val_accuracy: 0.9880\n",
            "Epoch 15/15\n",
            "53/53 [==============================] - 21s 380ms/step - loss: 0.0340 - accuracy: 0.9879 - val_loss: 0.0750 - val_accuracy: 0.9840\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy of model:\",model.evaluate(valid_ds))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T16:28:54.509989Z",
          "iopub.execute_input": "2024-02-13T16:28:54.511057Z",
          "iopub.status.idle": "2024-02-13T16:29:35.508552Z",
          "shell.execute_reply.started": "2024-02-13T16:28:54.510925Z",
          "shell.execute_reply": "2024-02-13T16:29:35.507197Z"
        },
        "trusted": true,
        "id": "rJ4J8ufNb2uf",
        "outputId": "0c36a273-fa02-4d4f-ae56-3dc3f7d89d81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 37ms/step - loss: 0.0750 - accuracy: 0.9840\n",
            "Accuracy of model: [0.07496581226587296, 0.984000027179718]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLES_TO_DISPLAY = 10\n",
        "\n",
        "test_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\n",
        "test_ds = test_ds.shuffle(buffer_size=batch_size * 8, seed=shuffle_seed).batch(\n",
        "    batch_size\n",
        ")\n",
        "\n",
        "test_ds = test_ds.map(lambda x, y: (add_noise(x, noises, scale=scale), y))\n",
        "\n",
        "for audios, labels in test_ds.take(1):\n",
        "    ffts = audio_to_fft(audios)\n",
        "    y_pred = model.predict(ffts)\n",
        "    rnd = np.random.randint(0, batch_size, SAMPLES_TO_DISPLAY)\n",
        "    audios = audios.numpy()[rnd, :, :]\n",
        "    labels = labels.numpy()[rnd]\n",
        "    y_pred = np.argmax(y_pred, axis=-1)[rnd]\n",
        "\n",
        "    for index in range(SAMPLES_TO_DISPLAY):\n",
        "        print(\n",
        "            \"Speaker:\\33{} {}\\33[0m\\tPredicted:\\33{} {}\\33[0m\".format(\n",
        "                \"[92m\" if labels[index] == y_pred[index] else \"[91m\",\n",
        "                class_names[labels[index]],\n",
        "                \"[92m\" if labels[index] == y_pred[index] else \"[91m\",\n",
        "                class_names[y_pred[index]],\n",
        "            )\n",
        "        )\n",
        "        if labels[index] ==y_pred[index]:\n",
        "            print(\"Welcome\")\n",
        "        else:\n",
        "            print(\"Sorry\")\n",
        "        print(\"The speaker is\" if labels[index] == y_pred[index] else \"\", class_names[y_pred[index]])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T16:29:41.821101Z",
          "iopub.execute_input": "2024-02-13T16:29:41.821555Z",
          "iopub.status.idle": "2024-02-13T16:29:46.187874Z",
          "shell.execute_reply.started": "2024-02-13T16:29:41.82152Z",
          "shell.execute_reply": "2024-02-13T16:29:46.186685Z"
        },
        "trusted": true,
        "id": "iNrkJvzUb2uf",
        "outputId": "40790956-4334-4d72-821a-4c9ef07d5490",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 43ms/step\n",
            "Speaker:\u001b[92m Magaret_Tarcher\u001b[0m\tPredicted:\u001b[92m Magaret_Tarcher\u001b[0m\n",
            "Welcome\n",
            "The speaker is Magaret_Tarcher\n",
            "Speaker:\u001b[92m Benjamin_Netanyau\u001b[0m\tPredicted:\u001b[92m Benjamin_Netanyau\u001b[0m\n",
            "Welcome\n",
            "The speaker is Benjamin_Netanyau\n",
            "Speaker:\u001b[92m Benjamin_Netanyau\u001b[0m\tPredicted:\u001b[92m Benjamin_Netanyau\u001b[0m\n",
            "Welcome\n",
            "The speaker is Benjamin_Netanyau\n",
            "Speaker:\u001b[92m Magaret_Tarcher\u001b[0m\tPredicted:\u001b[92m Magaret_Tarcher\u001b[0m\n",
            "Welcome\n",
            "The speaker is Magaret_Tarcher\n",
            "Speaker:\u001b[92m Jens_Stoltenberg\u001b[0m\tPredicted:\u001b[92m Jens_Stoltenberg\u001b[0m\n",
            "Welcome\n",
            "The speaker is Jens_Stoltenberg\n",
            "Speaker:\u001b[92m Jens_Stoltenberg\u001b[0m\tPredicted:\u001b[92m Jens_Stoltenberg\u001b[0m\n",
            "Welcome\n",
            "The speaker is Jens_Stoltenberg\n",
            "Speaker:\u001b[92m Benjamin_Netanyau\u001b[0m\tPredicted:\u001b[92m Benjamin_Netanyau\u001b[0m\n",
            "Welcome\n",
            "The speaker is Benjamin_Netanyau\n",
            "Speaker:\u001b[92m Julia_Gillard\u001b[0m\tPredicted:\u001b[92m Julia_Gillard\u001b[0m\n",
            "Welcome\n",
            "The speaker is Julia_Gillard\n",
            "Speaker:\u001b[92m Benjamin_Netanyau\u001b[0m\tPredicted:\u001b[92m Benjamin_Netanyau\u001b[0m\n",
            "Welcome\n",
            "The speaker is Benjamin_Netanyau\n",
            "Speaker:\u001b[92m Jens_Stoltenberg\u001b[0m\tPredicted:\u001b[92m Jens_Stoltenberg\u001b[0m\n",
            "Welcome\n",
            "The speaker is Jens_Stoltenberg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " def paths_to_dataset(audio_paths):\n",
        "    path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n",
        "    return tf.data.Dataset.zip((path_ds))\n",
        "\n",
        "def predict(path, labels):\n",
        "    test = paths_and_labels_to_dataset(path, labels)\n",
        "\n",
        "\n",
        "    test = test.shuffle(buffer_size=batch_size * 8, seed=shuffle_seed).batch(\n",
        "    batch_size\n",
        "    )\n",
        "    test = test.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "    test = test.map(lambda x, y: (add_noise(x, noises, scale=scale), y))\n",
        "\n",
        "    for audios, labels in test.take(1):\n",
        "        ffts = audio_to_fft(audios)\n",
        "        y_pred = model.predict(ffts)\n",
        "        rnd = np.random.randint(0, 1, 1)\n",
        "        audios = audios.numpy()[rnd, :]\n",
        "        labels = labels.numpy()[rnd]\n",
        "        y_pred = np.argmax(y_pred, axis=-1)[rnd]\n",
        "\n",
        "    for index in range(1):\n",
        "            print(\n",
        "            \"Speaker:\\33{} {}\\33[0m\\tPredicted:\\33{} {}\\33[0m\".format(\n",
        "            \"[92m\",y_pred[index],\n",
        "                \"[92m\", y_pred[index]\n",
        "                )\n",
        "            )\n",
        "\n",
        "            print(\"Speaker Predicted:\",class_names[y_pred[index]])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T16:29:53.534182Z",
          "iopub.execute_input": "2024-02-13T16:29:53.534658Z",
          "iopub.status.idle": "2024-02-13T16:29:53.547834Z",
          "shell.execute_reply.started": "2024-02-13T16:29:53.534624Z",
          "shell.execute_reply": "2024-02-13T16:29:53.546097Z"
        },
        "trusted": true,
        "id": "owydvp2Ib2uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = [\"../input/speaker-recognition-dataset/16000_pcm_speeches/Jens_Stoltenberg/1013.wav\"]\n",
        "labels = [\"unknown\"]\n",
        "try:\n",
        "    predict(path, labels)\n",
        "except:\n",
        "    print(\"Error! Check if the file correctly passed or not!\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-13T16:29:58.657033Z",
          "iopub.execute_input": "2024-02-13T16:29:58.657654Z",
          "iopub.status.idle": "2024-02-13T16:29:59.144758Z",
          "shell.execute_reply.started": "2024-02-13T16:29:58.657602Z",
          "shell.execute_reply": "2024-02-13T16:29:59.143808Z"
        },
        "trusted": true,
        "id": "rbtjDTH2b2ug",
        "outputId": "efd15a77-c48f-4c10-eb09-23d664b6ef8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n",
            "Speaker:\u001b[92m 2\u001b[0m\tPredicted:\u001b[92m 2\u001b[0m\n",
            "Speaker Predicted: Jens_Stoltenberg\n"
          ]
        }
      ]
    }
  ]
}